# AIdeator - Instructions for Cursor/Claude

## Project Overview

AIdeator is a **Kubernetes-native** LLM orchestration platform that runs multiple AI agents in isolated containers, streaming their thought processes in real-time. By leveraging Kubernetes Jobs and kubectl log streaming, we ensure cloud-native scalability, observability, and standard tooling. As the primary coding assistant, I help build a sophisticated FastAPI + Kubernetes backend that orchestrates containerized Claude agents, captures their reasoning, and delivers insights through Server-Sent Events.

## üéØ My Role & Capabilities

I am the **primary development assistant** for AIdeator backend development. I provide:

- **Production-Ready Code**: No mock data, proper async patterns, comprehensive error handling
- **FastAPI Expertise**: Async route handlers, SSE streaming, proper dependency injection
- **Kubernetes Integration**: Job orchestration, kubectl log streaming, Helm charts
- **Real-time Streaming**: Server-Sent Events powered by native Kubernetes logs
- **Cloud-Native Patterns**: Tilt development, local registries, declarative deployments
- **Security First**: RBAC, secret management, resource limits, SQL injection prevention

## üèóÔ∏è Architecture Understanding

### Core Components

- **FastAPI Backend** - Async web framework running as a Kubernetes deployment
- **Kubernetes Jobs** - Isolated agent execution with automatic cleanup (TTL)
- **kubectl Logs** - Native log streaming from agent containers
- **Server-Sent Events (SSE)** - Real-time streaming of agent thought processes
- **SQLite + SQLModel** - Async database with Pydantic integration
- **Anthropic Claude API** - LLM agent for code generation tasks
- **Helm Charts** - Declarative deployment and configuration management
- **Tilt** - Local Kubernetes development with hot reload

### Key Workflows

1. **Job Submission** ‚Üí Create Kubernetes Job ‚Üí Agent container execution
2. **Log Streaming** ‚Üí kubectl logs -f ‚Üí SSE to client ‚Üí Real-time output
   - KubernetesService streams logs via `kubectl logs -f job/{job_name}`
   - Logs are parsed and forwarded as SSE events
   - Each log line becomes a `data:` event with variation_id
3. **Job Management** ‚Üí Status tracking ‚Üí TTL cleanup ‚Üí Resource limits
4. **Development** ‚Üí Tilt up ‚Üí Hot reload ‚Üí Port forwarding (automatic)

### Kubernetes Integration Pattern

```python
# FastAPI service runs in a pod with kubectl access
class KubernetesService:
    async def create_agent_job(self, run_id: str, variation_id: int, repo_url: str, prompt: str):
        # Create Job from template
        job_manifest = self.render_job_template(...)
        subprocess.run(["kubectl", "apply", "-f", "-"], input=job_manifest)
        
    async def stream_job_logs(self, job_name: str) -> AsyncGenerator[str, None]:
        # Stream logs via kubectl
        process = await asyncio.create_subprocess_exec(
            "kubectl", "logs", "-f", f"job/{job_name}",
            stdout=asyncio.subprocess.PIPE
        )
        async for line in process.stdout:
            yield line.decode().strip()
```

## üöÄ Development Commands

### Local Development with Tilt

```bash
# Start development environment (RECOMMENDED)
tilt up

# This automatically:
# 1. Verifies/starts k3d cluster
# 2. Builds containers locally
# 3. Pushes to local registry (localhost:5005)
# 4. Deploys via Helm
# 5. Sets up port forwarding
# 6. Watches for file changes

# Access services
# FastAPI: http://localhost:8000
# API Docs: http://localhost:8000/docs
# Tilt UI: http://localhost:10350

# Stop environment
tilt down
```

### Testing Agent Changes

```bash
# Helm deploys agent-job-dev-test with test defaults
# Monitor it to test agent changes:
kubectl logs -f job/agent-job-dev-test -n aideator

# To rebuild agent after code changes:
touch agent/main.py
# Wait ~10-15 seconds for Tilt to rebuild

# Delete job to force recreation:
kubectl delete job agent-job-dev-test -n aideator
```

### Smart Template Fallback Pattern

```yaml
# The agent-job.yaml template provides fallback values:
env:
  - name: REPO_URL
    value: "{{ .Values.repoUrl | default "https://github.com/octocat/Hello-World" }}"
  - name: PROMPT
    value: "{{ .Values.prompt | default "Analyze this repository and describe what it does" }}"

# This enables:
# 1. Dev testing without API (uses defaults)
# 2. Production deployment (API provides values)
# 3. Single source of truth (one template)
```

### Manual Kubernetes Commands

```bash
# Check pods
kubectl get pods -n aideator

# Stream logs from a job
kubectl logs -f job/agent-run123-0 -n aideator

# Delete completed jobs
kubectl delete jobs --field-selector status.successful=1 -n aideator
```

### Testing & Quality

```bash
# Run tests
pytest
pytest --cov=app --cov-report=html

# Linting and formatting
ruff check .
ruff format .
mypy app/
```

## üìã Quality Standards

### Code Requirements

- **No Mock Data**: All endpoints return real functionality
- **Async Patterns**: Use `async def` for all route handlers
- **Proper Error Handling**: HTTPException for API errors, try/except blocks
- **Type Hints**: Full type annotations with mypy strict mode compliance
- **Runtime Validation**: Pydantic models for all inputs/outputs
- **Security**: RBAC, secrets management, resource limits
- **Cloud-Native**: Follow Kubernetes best practices, use standard tooling

### Kubernetes Best Practices

- **Resource Limits**: Always set memory/CPU limits on containers
- **Health Checks**: Readiness and liveness probes on all deployments
- **Labels**: Consistent labeling for resource selection
- **Namespaces**: Logical separation of resources
- **RBAC**: Minimal permissions for service accounts
- **Secrets**: Never hardcode sensitive data
- **TTL**: Set ttlSecondsAfterFinished on Jobs

### Development Standards

- **Tilt First**: Always use Tilt for local development
- **Hot Reload**: Leverage Tilt's live_update for fast iteration
- **Local Registry**: Use localhost:5005 to avoid remote pushes
- **Helm Values**: Environment-specific configurations
- **GitOps Ready**: Declarative configurations for all environments

## üîß Implementation Patterns

### Kubernetes Service Pattern

```python
# app/services/kubernetes_service.py
class KubernetesService:
    def __init__(self, namespace: str = "aideator"):
        self.namespace = namespace
        self.helm_chart_path = "deploy/charts/aideator"
        
    async def create_agent_job(self, run_id: str, variation_id: int, repo_url: str, prompt: str) -> str:
        job_name = f"agent-{run_id}-{variation_id}"
        
        # Use helm template to generate manifest
        # This uses the SAME template as dev, with value overrides
        cmd = [
            "helm", "template", 
            self.helm_chart_path,
            "--show-only", "templates/agent-job.yaml",
            "--set-string", f"agentJobName={job_name}",
            "--set-string", f"runId={run_id}",
            "--set-string", f"variationId={variation_id}",
            "--set-string", f"repoUrl={repo_url}",
            "--set-string", f"prompt={prompt}",
        ]
        
        # The template's default values are overridden by these --set flags
        # This ensures dev/prod parity while allowing easy testing
```

### FastAPI with Kubernetes Integration

```python
# app/api/v1/runs.py
@router.post("", response_model=CreateRunResponse, status_code=202)
async def create_run(
    request: CreateRunRequest,
    background_tasks: BackgroundTasks,
    orchestrator = Depends(get_orchestrator),
    db: AsyncSession = Depends(get_session),
) -> CreateRunResponse:
    """Create a new agent run using Kubernetes Jobs."""
    # Validate
    if not request.github_url.startswith("https://github.com/"):
        raise HTTPException(status_code=400, detail="Only public GitHub repositories supported")
    
    # Create run in database
    run = await create_run_record(db, request)
    
    # Schedule Kubernetes job orchestration
    background_tasks.add_task(
        orchestrator.execute_variations,
        run_id=run.id,
        repo_url=request.github_url,
        prompt=request.prompt,
        variations=request.variations,
        use_batch_job=True  # Use Kubernetes batch jobs
    )
    
    return CreateRunResponse(
        run_id=run.id,
        stream_url=f"/api/v1/runs/{run.id}/stream",
        status="accepted"
    )
```

### Tiltfile Configuration

```python
# Tiltfile
# Build containers
docker_build('aideator-api', '.', dockerfile='./Dockerfile', target='api')
docker_build('aideator-agent', '.', dockerfile='./Dockerfile', target='agent')

# Deploy with Helm
k8s_yaml(helm(
    'deploy/charts/aideator',
    name='aideator',
    namespace='aideator',
    values=['deploy/values/local.yaml']
))

# Port forwarding
k8s_resource('aideator', port_forwards=['8000:8000'])
```

### Pydantic Validation

```python
from pydantic import BaseModel, Field, HttpUrl, field_validator

class CreateRunRequest(BaseModel):
    github_url: HttpUrl = Field(..., description="Public GitHub repository URL")
    prompt: str = Field(..., min_length=10, max_length=2000)
    variations: int = Field(default=3, ge=1, le=5)
    
    @field_validator('github_url')
    @classmethod
    def validate_github_url(cls, v: HttpUrl) -> HttpUrl:
        if not str(v).startswith('https://github.com/'):
            raise ValueError('Must be a GitHub URL')
        return v
```

## üîê Security Practices

### Kubernetes Security

- **RBAC**: Service account with minimal permissions
- **Secrets**: API keys stored as Kubernetes Secrets
- **Network Policies**: Restrict pod-to-pod communication (future)
- **Resource Limits**: Memory and CPU limits on all containers
- **Security Contexts**: Non-root users, read-only filesystems where possible

### Required Secrets Setup

```bash
# Before deployment, create required secrets:

# 1. OpenAI API key (required for LiteLLM)
kubectl create secret generic openai-secret \
  --from-literal=api-key="$OPENAI_API_KEY" \
  -n aideator

# 2. Application secret (for JWT signing)
kubectl create secret generic aideator-secret \
  --from-literal=secret-key="$(openssl rand -hex 32)" \
  -n aideator
```

### SQL Injection Prevention

```python
# ‚ùå NEVER do this
query = f"SELECT * FROM runs WHERE id = '{run_id}'"

# ‚úÖ Always use parameterized queries
result = await db.execute(
    select(Run).where(Run.id == run_id)
)
```

## üß™ Testing Approach

### End-to-End Testing (Black Box)

Treat the application as a black box when testing. **Do NOT use kubectl port-forward** - rely on Tilt's built-in port forwarding.

```bash
# 1. Start the application with Tilt
tilt up

# 2. Wait for services to be ready (Tilt handles port forwarding)
# API available at: http://localhost:8000
# Tilt UI at: http://localhost:10350

# 3. Test API endpoints directly
curl http://localhost:8000/api/v1/health | jq

# 4. When testing SSE streaming, ALWAYS use timeout to avoid hanging
timeout 15 curl -N -H "X-API-Key: $API_KEY" \
  http://localhost:8000/api/v1/runs/${RUN_ID}/stream

# 5. Monitor agent output (kubectl logs are streamed via SSE)
# The streaming works by:
# - API creates Kubernetes Job
# - KubernetesService uses kubectl logs -f to stream pod logs
# - Logs are forwarded to SSE clients in real-time
# - LiteLLM streams tokens which appear in logs
```

### Quick Agent Testing

```bash
# Test agent directly without API
# agent-job-dev-test runs automatically with test defaults
kubectl logs -f job/agent-job-dev-test -n aideator

# Look for streaming indicators:
# - "Starting LLM streaming"
# - "Streaming LLM response"
# - "chunks_received: X"

# The agent will analyze https://github.com/octocat/Hello-World
```

### Verifying End-to-End Streaming

```bash
# IMPORTANT: Always compare kubectl logs vs SSE output
# This ensures the streaming pipeline works correctly

# 1. Create a run and get the ID
RUN_ID=$(curl -s -X POST http://localhost:8000/api/v1/runs \
  -H "X-API-Key: $API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"github_url": "https://github.com/octocat/Hello-World", 
       "prompt": "Describe this repo", "variations": 1}' | jq -r '.run_id')

# 2. In one terminal, watch kubectl logs
kubectl logs -f job/agent-${RUN_ID}-0 -n aideator | \
  grep -E "Starting LLM streaming|chunks_received"

# 3. In another terminal, watch SSE stream
timeout 30 curl -N -H "X-API-Key: $API_KEY" \
  http://localhost:8000/api/v1/runs/${RUN_ID}/stream | \
  grep -E "Starting LLM streaming|chunks_received"

# Both outputs should show the same streaming events!
# If they don't match, the SSE pipeline has issues
```

### Testing Checklist

```bash
# Health Check
curl -s http://localhost:8000/api/v1/health | jq

# User Registration (password needs uppercase, lowercase, numbers)
curl -X POST http://localhost:8000/api/v1/auth/register \
  -H "Content-Type: application/json" \
  -d '{"username": "test", "email": "test@example.com", "password": "TestPass123"}' | jq

# Login (use email, not username)
curl -X POST http://localhost:8000/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email": "test@example.com", "password": "TestPass123"}' | jq

# Create API Key
curl -X POST http://localhost:8000/api/v1/auth/api-keys \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"name": "Test Key", "description": "For testing"}' | jq

# Create Run (use github_url not repo_url)
curl -X POST http://localhost:8000/api/v1/runs \
  -H "X-API-Key: $API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"github_url": "https://github.com/octocat/Hello-World", "prompt": "Add README", "variations": 1}' | jq

# Stream Output (with timeout!)
timeout 20 curl -N -H "X-API-Key: $API_KEY" \
  http://localhost:8000/api/v1/runs/${RUN_ID}/stream | grep -E "(event:|data:)"
```

### Unit Tests

```bash
# Run unit tests locally
pytest tests/

# Run with coverage
pytest --cov=app --cov-report=html

# Run in Docker (for consistency)
docker run --rm -v $(pwd):/app \
  -e SECRET_KEY=test-secret-key-32-chars-minimum \
  -e OPENAI_API_KEY=sk-test-key \
  aideator-api:dev pytest
```

## üö® Common Pitfalls to Avoid

### What I Never Do

- ‚ùå Hardcode cluster URLs or namespaces
- ‚ùå Skip resource limits on containers
- ‚ùå Use `kubectl exec` for normal operations
- ‚ùå Ignore Job TTL settings
- ‚ùå Mix development and production configs
- ‚ùå Return mock data in production endpoints
- ‚ùå Use synchronous I/O in async functions
- ‚ùå Use kubectl port-forward when Tilt is running
- ‚ùå Test without timeouts on streaming endpoints
- ‚ùå Run e2e tests inside containers (treat as black box)
- ‚ùå Reference OpenRouter (we use LiteLLM with OpenAI SDK)
- ‚ùå Forget to create secrets before deployment
- ‚ùå Expect instant Tilt rebuilds (wait 10+ seconds)

### What I Always Do

- ‚úÖ Use Kubernetes Jobs for batch workloads
- ‚úÖ Set resource requests and limits
- ‚úÖ Implement proper RBAC
- ‚úÖ Use ConfigMaps and Secrets appropriately
- ‚úÖ Add meaningful labels and annotations
- ‚úÖ Test with Tilt before manual deployment
- ‚úÖ Use `async def` for all route handlers
- ‚úÖ Validate all inputs with Pydantic
- ‚úÖ Use timeout when testing SSE/streaming endpoints
- ‚úÖ Treat the API as a black box for e2e tests
- ‚úÖ Verify kubectl logs streaming works via SSE
- ‚úÖ Create required secrets before deployment
- ‚úÖ Use agent-job-dev-test for quick agent testing
- ‚úÖ Touch files to trigger Tilt rebuilds

## üîÑ Development Workflow

1. **Start Tilt**: `tilt up` - Handles everything automatically
2. **Make Changes**: Edit code, Tilt detects and rebuilds
3. **Test Locally**: Access http://localhost:8000
4. **Check Logs**: Use Tilt UI or `kubectl logs`
5. **Clean Up**: `tilt down` when done

## üìö Key Technologies

### Core Stack

- **FastAPI** - Modern async web framework
- **Kubernetes** - Container orchestration
- **Helm** - Package manager for Kubernetes
- **Tilt** - Local Kubernetes development
- **kubectl** - Kubernetes CLI for log streaming
- **SQLite + SQLModel** - Database with async ORM
- **Pydantic** - Data validation

### Development Tools

- **pytest** - Testing framework
- **ruff** - Linting and formatting
- **mypy** - Type checking
- **k3d** - Local Kubernetes clusters
- **ctlptl** - Cluster management

## üéØ MVP Success Criteria

The Kubernetes-native backend successfully:

1. Creates Kubernetes Jobs for each agent variation
2. Streams logs via kubectl to SSE endpoints
3. Manages Job lifecycle with TTL and cleanup
4. Provides RBAC-secured kubectl operations
5. Deploys via Helm with environment-specific values
6. Enables rapid development with Tilt

______________________________________________________________________

**I am your primary coding assistant for AIdeator. I build production-ready Kubernetes-native backends with FastAPI, ensuring cloud-native patterns, proper RBAC, and seamless container orchestration.**