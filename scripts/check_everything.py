#!/usr/bin/env python3
"""
üöÄ AIdeator Complete Environment & Architecture Checker

This script validates the entire AIdeator development environment and tests
the decoupled background processing architecture that mimics:

üìö BACKGROUND PROCESSING REFERENCES:
‚Ä¢ OpenAI Codex Background Agents (current coding feature in OpenAI's interface)
‚Ä¢ Cursor.com Background Agents (autonomous coding workflows)
‚Ä¢ Similar to how ChatGPT Code Analysis works in background

üèóÔ∏è ARCHITECTURE OVERVIEW:
The workflow separates task submission from task monitoring:

1. TASK SUBMISSION (Main Page)
   User Input ‚Üí POST /api/v1/runs ‚Üí Database ‚Üí Kubernetes Jobs ‚Üí Background Processing

2. BACKGROUND PROCESSING  
   K8s Jobs ‚Üí Write to SQL (agent_outputs table) ‚Üí Continue independently

3. TASK MONITORING (Task Detail Page)
   User Navigation ‚Üí GET /api/v1/tasks/{id} ‚Üí Read SQL ‚Üí Display Progress

This allows users to:
- Submit work and get immediate acknowledgment
- Check progress later via separate interface  
- Jobs run completely independently
- All communication flows through PostgreSQL for reliability

üéØ WHAT THIS SCRIPT VALIDATES:
‚úÖ Environment configuration (API keys, settings)
‚úÖ Database schema and connectivity
‚úÖ Redis cache functionality
‚úÖ Kubernetes cluster health
‚úÖ API endpoint separation and functionality
‚úÖ Development mode authentication bypass
‚úÖ Background job workflow simulation
"""

import asyncio
import json
import subprocess
import sys
from datetime import datetime
from pathlib import Path

# Add the app directory to Python path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import httpx
    import psycopg
    import redis
    from sqlalchemy import text

    from app.core.config import get_settings
    from app.core.database import engine
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("üí° Run: uv sync")
    sys.exit(1)


class Colors:
    """Terminal colors for beautiful output."""
    GREEN = "\033[92m"
    RED = "\033[91m"
    YELLOW = "\033[93m"
    BLUE = "\033[94m"
    PURPLE = "\033[95m"
    CYAN = "\033[96m"
    WHITE = "\033[97m"
    GRAY = "\033[90m"
    ENDC = "\033[0m"
    BOLD = "\033[1m"


class EnvironmentChecker:
    """Comprehensive environment and architecture checker."""

    def __init__(self):
        self.results: list[tuple[str, bool, str]] = []
        self.base_url = "http://localhost:8000"

    def print_header(self, title: str, emoji: str = "üîç"):
        """Print section header with style."""
        print(f"\n{Colors.PURPLE}{'='*70}{Colors.ENDC}")
        print(f"{Colors.PURPLE}{emoji} {title.center(66)} {Colors.ENDC}")
        print(f"{Colors.PURPLE}{'='*70}{Colors.ENDC}\n")

    def print_success(self, message: str):
        """Print success message."""
        print(f"{Colors.GREEN}‚úÖ {message}{Colors.ENDC}")

    def print_error(self, message: str):
        """Print error message."""
        print(f"{Colors.RED}‚ùå {message}{Colors.ENDC}")

    def print_warning(self, message: str):
        """Print warning message."""
        print(f"{Colors.YELLOW}‚ö†Ô∏è  {message}{Colors.ENDC}")

    def print_info(self, message: str):
        """Print info message."""
        print(f"{Colors.BLUE}‚ÑπÔ∏è  {message}{Colors.ENDC}")

    def print_workflow(self, step: str, description: str):
        """Print workflow step."""
        print(f"{Colors.CYAN}üîÑ {step}:{Colors.ENDC} {description}")

    def record_result(self, test_name: str, passed: bool, details: str = ""):
        """Record test result."""
        self.results.append((test_name, passed, details))

    def check_environment_files(self) -> bool:
        """
        üîß ENVIRONMENT CONFIGURATION
        
        Validates that required environment files exist and contain proper API keys.
        This is crucial for the background agents to communicate with LLM providers.
        """
        self.print_header("Environment Configuration", "üîß")

        success = True

        # Check .env file
        env_path = Path(".env")
        if not env_path.exists():
            self.print_error(".env file not found")
            self.record_result("Environment Files", False, "Missing .env file")
            return False

        self.print_success(".env file found")

        # Read and validate API keys
        with open(env_path) as f:
            content = f.read()

        required_keys = {
            "OPENAI_API_KEY": "sk-",
            "ANTHROPIC_API_KEY": "sk-ant-"
        }

        for key, prefix in required_keys.items():
            if key not in content:
                self.print_error(f"Missing {key}")
                success = False
                continue

            # Extract value
            lines = [line for line in content.split("\n") if line.startswith(f"{key}=")]
            if lines:
                value = lines[0].split("=", 1)[1].strip()
                if value and value.startswith(prefix):
                    self.print_success(f"{key} format is valid")
                elif value == "placeholder-set-via-dotenv":
                    self.print_warning(f"{key} is placeholder (should work in dev mode)")
                else:
                    self.print_warning(f"{key} format looks suspicious")
            else:
                self.print_error(f"{key} not found in .env")
                success = False

        # Check development mode files
        if Path("TASK-RUN-ARCHITECTURE.md").exists():
            self.print_success("Architecture documentation exists")
        else:
            self.print_warning("Architecture documentation missing")

        self.record_result("Environment Files", success)
        return success

    def check_application_settings(self) -> bool:
        """
        ‚öôÔ∏è APPLICATION SETTINGS
        
        Validates that simple_dev_mode is enabled and settings are properly configured
        for the background processing workflow.
        """
        self.print_header("Application Settings", "‚öôÔ∏è")

        try:
            settings = get_settings()

            # Core settings validation
            if settings.simple_dev_mode:
                self.print_success("Simple dev mode ENABLED (auth bypass active)")
            else:
                self.print_error("Simple dev mode DISABLED (will cause auth issues)")
                self.record_result("Application Settings", False, "Dev mode disabled")
                return False

            if settings.debug:
                self.print_success("Debug mode enabled")
            else:
                self.print_info("Debug mode disabled")

            # API key validation
            key_status = []
            if settings.openai_api_key:
                if settings.openai_api_key.startswith("sk-"):
                    self.print_success("OpenAI API key loaded and valid")
                    key_status.append("openai")
                else:
                    self.print_warning(f"OpenAI key format: {settings.openai_api_key[:20]}...")

            if settings.anthropic_api_key:
                if settings.anthropic_api_key.startswith("sk-ant-"):
                    self.print_success("Anthropic API key loaded and valid")
                    key_status.append("anthropic")
                else:
                    self.print_warning(f"Anthropic key format: {settings.anthropic_api_key[:20]}...")

            # Connection strings
            self.print_info(f"Database: {settings.database_url.split('@')[1] if '@' in settings.database_url else settings.database_url}")
            self.print_info(f"Redis: {settings.redis_url}")

            if len(key_status) >= 1:
                self.print_success(f"‚ú® Background agents can use: {', '.join(key_status)}")
            else:
                self.print_warning("No valid API keys for background agents")

            self.record_result("Application Settings", True)
            return True

        except Exception as e:
            self.print_error(f"Settings validation failed: {e}")
            self.record_result("Application Settings", False, str(e))
            return False

    async def check_database_schema(self) -> bool:
        """
        üóÑÔ∏è DATABASE ARCHITECTURE
        
        Validates the PostgreSQL schema supports the background processing workflow:
        ‚Ä¢ runs table: Stores task metadata and job configuration
        ‚Ä¢ agent_outputs table: Central communication hub for background agents
        ‚Ä¢ Proper indexes for real-time querying
        """
        self.print_header("Database Architecture", "üóÑÔ∏è")

        try:
            # Test connection
            async with engine.begin() as conn:
                result = await conn.execute(text("SELECT version()"))
                version = result.scalar()
                self.print_success(f"Connected: {version.split(',')[0]}")

            # Check tables exist
            async with engine.begin() as conn:
                result = await conn.execute(text("""
                    SELECT table_name 
                    FROM information_schema.tables 
                    WHERE table_schema = 'public'
                    ORDER BY table_name
                """))
                tables = [row[0] for row in result.fetchall()]

                if tables:
                    self.print_success(f"Found {len(tables)} tables")

                    # Core tables for background processing
                    required_tables = {
                        "runs": "Task metadata and Kubernetes job config",
                        "agent_outputs": "Background agent communication hub",
                        "users": "User management (dev mode bypassed)"
                    }

                    missing_tables = []
                    for table, description in required_tables.items():
                        if table in tables:
                            self.print_success(f"{table}: {description}")
                        else:
                            missing_tables.append(table)
                            self.print_error(f"Missing {table}")

                    if missing_tables:
                        self.print_error("üí° Run: tilt trigger database-migrate")
                        self.record_result("Database Schema", False, f"Missing: {missing_tables}")
                        return False

                    # Check runs table schema (critical for task-run architecture)
                    if "runs" in tables:
                        result = await conn.execute(text("""
                            SELECT column_name, data_type, is_nullable
                            FROM information_schema.columns 
                            WHERE table_name = 'runs' AND table_schema = 'public'
                            ORDER BY ordinal_position
                        """))
                        columns = {row[0]: row[1] for row in result.fetchall()}

                        required_columns = {
                            "id": "Task identifier (same as run_id)",
                            "github_url": "Repository for background processing",
                            "prompt": "User task description",
                            "task_status": "Task outcome (open/completed/failed)",
                            "variations": "Number of background agents",
                            "status": "Kubernetes job status"
                        }

                        missing_columns = []
                        for col, description in required_columns.items():
                            if col in columns:
                                self.print_success(f"  ‚úì {col}: {description}")
                            else:
                                missing_columns.append(col)
                                self.print_error(f"  ‚úó Missing {col}")

                        if missing_columns:
                            self.print_warning("Schema needs update for task-run architecture")

                    # Check agent_outputs table (central to background processing)
                    if "agent_outputs" in tables:
                        result = await conn.execute(text("""
                            SELECT COUNT(*) FROM agent_outputs
                        """))
                        count = result.scalar()
                        self.print_info(f"Agent outputs stored: {count}")
                        self.print_workflow("Background Flow", "Agents write ‚Üí agent_outputs ‚Üí Frontend reads")

                else:
                    self.print_error("No tables found - database needs initialization")
                    self.record_result("Database Schema", False, "Empty database")
                    return False

            self.record_result("Database Schema", True)
            return True

        except Exception as e:
            self.print_error(f"Database check failed: {e}")
            self.record_result("Database Schema", False, str(e))
            return False

    async def check_redis_cache(self) -> bool:
        """
        üóÑÔ∏è REDIS CACHE
        
        Redis provides real-time message queuing for the background processing workflow.
        Not critical for core functionality but enhances performance.
        """
        self.print_header("Redis Cache", "üì°")

        try:
            settings = get_settings()
            if not settings.redis_url:
                self.print_warning("Redis URL not configured")
                self.record_result("Redis Cache", False, "Not configured")
                return False

            # Connect to Redis
            if settings.redis_url.startswith("redis://localhost:"):
                port = int(settings.redis_url.split(":")[-1].split("/")[0])
                r = redis.Redis(host="localhost", port=port, decode_responses=True)
            else:
                r = redis.from_url(settings.redis_url, decode_responses=True)

            # Test operations
            r.ping()
            self.print_success("Redis connection successful")

            # Test read/write for background messaging
            test_key = f"background_test_{datetime.now().timestamp()}"
            r.set(test_key, json.dumps({"type": "agent_output", "content": "test"}), ex=10)
            value = r.get(test_key)

            if value:
                self.print_success("Redis read/write operations work")
                self.print_workflow("Message Flow", "Agents ‚Üí Redis ‚Üí WebSocket ‚Üí Frontend")
            else:
                self.print_warning("Redis operations failed")

            r.delete(test_key)
            self.record_result("Redis Cache", True)
            return True

        except Exception as e:
            self.print_error(f"Redis check failed: {e}")
            self.record_result("Redis Cache", False, str(e))
            return False

    async def check_kubernetes_cluster(self) -> bool:
        """
        ‚ò∏Ô∏è KUBERNETES CLUSTER
        
        Validates the Kubernetes cluster that runs background agents.
        Each task spawns isolated containers that process work independently.
        """
        self.print_header("Kubernetes Cluster", "‚ò∏Ô∏è")

        try:
            # Check namespace
            result = subprocess.run(
                ["kubectl", "get", "namespace", "aideator"],
                check=False, capture_output=True, text=True
            )
            if result.returncode != 0:
                self.print_error("aideator namespace not found")
                self.record_result("Kubernetes Cluster", False, "Namespace missing")
                return False

            self.print_success("aideator namespace exists")

            # Check core services
            result = subprocess.run(
                ["kubectl", "get", "pods", "-n", "aideator", "--no-headers"],
                check=False, capture_output=True, text=True
            )

            if result.returncode != 0:
                self.print_error("Failed to get pods")
                self.record_result("Kubernetes Cluster", False, "Pod access failed")
                return False

            pods = result.stdout.strip().split("\n") if result.stdout.strip() else []
            services = {
                "aideator-api": "REST API for task submission/monitoring",
                "aideator-database": "PostgreSQL for persistent storage",
                "aideator-redis": "Redis for real-time messaging",
                "aideator-litellm": "LLM gateway for background agents"
            }

            running_services = []
            for pod in pods:
                if pod.strip():
                    parts = pod.split()
                    name, ready, status = parts[0], parts[1], parts[2]

                    service_name = None
                    for service in services:
                        if name.startswith(service):
                            service_name = service
                            break

                    if status == "Running" and "/" in ready:
                        ready_count, total_count = ready.split("/")
                        if ready_count == total_count:
                            self.print_success(f"{service_name}: {status} ({ready})")
                            if service_name:
                                running_services.append(service_name)
                                self.print_info(f"  ‚Üí {services[service_name]}")
                        else:
                            self.print_warning(f"{service_name}: {status} ({ready})")
                    elif status == "Terminating":
                        self.print_info(f"{name}: {status} (cleanup in progress)")
                    else:
                        self.print_warning(f"{name}: {status} ({ready})")

            # Check for background job capabilities
            result = subprocess.run(
                ["kubectl", "get", "clusterrole", "aideator-agent-runner"],
                check=False, capture_output=True, text=True
            )

            if result.returncode == 0:
                self.print_success("Background job permissions configured")
                self.print_workflow("Job Flow", "API ‚Üí Creates K8s Job ‚Üí Agent Container ‚Üí Processes Task")
            else:
                self.print_warning("Background job permissions may be missing")

            if len(running_services) >= 3:  # API, DB, Redis minimum
                self.print_success("‚ú® Cluster ready for background processing")
                self.record_result("Kubernetes Cluster", True)
                return True
            self.print_error("Not enough services running for background processing")
            self.record_result("Kubernetes Cluster", False, "Insufficient services")
            return False

        except FileNotFoundError:
            self.print_error("kubectl not found - Kubernetes CLI not installed")
            self.record_result("Kubernetes Cluster", False, "kubectl missing")
            return False
        except Exception as e:
            self.print_error(f"Kubernetes check failed: {e}")
            self.record_result("Kubernetes Cluster", False, str(e))
            return False

    async def check_api_architecture(self) -> bool:
        """
        üåê API ARCHITECTURE
        
        Tests the separated API endpoints that implement the background processing workflow:
        ‚Ä¢ POST /api/v1/runs: Task submission (like OpenAI Codex "Run" button)  
        ‚Ä¢ GET /api/v1/tasks: Task monitoring (like Cursor.com background status)
        ‚Ä¢ Authentication bypass in development mode
        """
        self.print_header("API Architecture", "üåê")

        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                # Test 1: Health check
                response = await client.get(f"{self.base_url}/health")
                if response.status_code == 200:
                    self.print_success("API health endpoint responding")
                else:
                    self.print_error(f"Health check failed: {response.status_code}")
                    self.record_result("API Architecture", False, "Health check failed")
                    return False

                # Test 2: Task listing (monitoring side)
                response = await client.get(f"{self.base_url}/api/v1/tasks")
                if response.status_code == 200:
                    data = response.json()
                    self.print_success("Tasks endpoint accessible (auth bypassed)")
                    self.print_info(f"Current tasks in system: {len(data.get('tasks', []))}")
                    self.print_workflow("Monitoring Flow", "Frontend ‚Üí GET /api/v1/tasks ‚Üí Database ‚Üí Task List")
                elif response.status_code == 401:
                    self.print_error("Authentication required - dev mode not working")
                    self.record_result("API Architecture", False, "Auth bypass failed")
                    return False
                else:
                    self.print_error(f"Tasks endpoint failed: {response.status_code}")
                    self.record_result("API Architecture", False, f"Tasks endpoint: {response.status_code}")
                    return False

                # Test 3: Run creation (submission side)
                test_run = {
                    "github_url": "https://github.com/fastapi/fastapi",
                    "prompt": "Test background processing workflow validation",
                    "model_variants": [
                        {
                            "model_definition_id": "gpt-4o-mini",
                            "temperature": 0.1,
                            "max_tokens": 1000
                        }
                    ],
                    "use_claude_code": False,
                    "agent_mode": "litellm"
                }

                response = await client.post(f"{self.base_url}/api/v1/runs", json=test_run)
                if response.status_code == 202:  # Accepted for processing
                    data = response.json()
                    run_id = data.get("run_id")
                    self.print_success(f"Run creation successful: {run_id}")
                    self.print_workflow("Submission Flow", "Frontend ‚Üí POST /api/v1/runs ‚Üí K8s Jobs ‚Üí Background Processing")

                    # Test 4: Task detail endpoint
                    await asyncio.sleep(1)  # Brief pause for database write
                    response = await client.get(f"{self.base_url}/api/v1/tasks/{run_id}")
                    if response.status_code == 200:
                        task_data = response.json()
                        self.print_success("Task detail endpoint works")
                        self.print_info(f"Task status: {task_data.get('task_status', 'unknown')}")

                        # Test 5: Agent outputs endpoint
                        response = await client.get(f"{self.base_url}/api/v1/tasks/{run_id}/outputs")
                        if response.status_code == 200:
                            outputs = response.json()
                            self.print_success("Agent outputs endpoint accessible")
                            self.print_info(f"Background agent outputs: {len(outputs)}")

                            if outputs:
                                latest = outputs[-1]
                                self.print_workflow("Background Communication", f"Agent ‚Üí SQL ‚Üí Output: {latest.get('output_type', 'unknown')}")
                            else:
                                self.print_workflow("Background Communication", "Agents ‚Üí SQL ‚Üí (no outputs yet)")
                        else:
                            self.print_warning("Agent outputs endpoint failed")
                    else:
                        self.print_warning("Task detail endpoint failed")

                else:
                    self.print_error(f"Run creation failed: {response.status_code}")
                    if response.status_code == 422:
                        details = response.json()
                        self.print_info(f"Validation error: {details}")
                    self.record_result("API Architecture", False, f"Run creation: {response.status_code}")
                    return False

                # Test 6: OpenAPI documentation
                response = await client.get(f"{self.base_url}/docs")
                if response.status_code == 200:
                    self.print_success("API documentation accessible")
                    self.print_info("üí° View full API at: http://localhost:8000/docs")

                self.print_success("‚ú® API architecture matches OpenAI Codex / Cursor.com pattern")
                self.record_result("API Architecture", True)
                return True

        except Exception as e:
            self.print_error(f"API architecture test failed: {e}")
            self.record_result("API Architecture", False, str(e))
            return False

    async def simulate_background_workflow(self) -> bool:
        """
        ü§ñ BACKGROUND WORKFLOW SIMULATION
        
        Simulates the complete background processing workflow:
        1. Task submission (like clicking "Run" in OpenAI Codex)
        2. Background job creation
        3. Agent output monitoring (like Cursor.com status updates)
        4. Task completion detection
        """
        self.print_header("Background Workflow Simulation", "ü§ñ")

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                self.print_workflow("Step 1", "Simulating task submission...")

                # Create a test task
                workflow_test = {
                    "github_url": "https://github.com/python/cpython",
                    "prompt": "Background workflow validation - add error handling to a simple function",
                    "model_variants": [
                        {
                            "model_definition_id": "gpt-4o-mini",
                            "temperature": 0.2,
                            "max_tokens": 2000
                        }
                    ],
                    "use_claude_code": False,
                    "agent_mode": "litellm"
                }

                # Submit task
                response = await client.post(f"{self.base_url}/api/v1/runs", json=workflow_test)
                if response.status_code != 202:
                    self.print_error(f"Task submission failed: {response.status_code}")
                    self.record_result("Background Workflow", False, "Submission failed")
                    return False

                data = response.json()
                task_id = data["run_id"]
                websocket_url = data.get("websocket_url", "")

                self.print_success(f"‚úÖ Task submitted: {task_id}")
                self.print_info(f"WebSocket URL: {websocket_url}")

                self.print_workflow("Step 2", "Checking background job creation...")

                # Check if task appears in listing
                await asyncio.sleep(2)
                response = await client.get(f"{self.base_url}/api/v1/tasks")
                if response.status_code == 200:
                    tasks_data = response.json()
                    task_found = any(task["id"] == task_id for task in tasks_data.get("tasks", []))

                    if task_found:
                        self.print_success("‚úÖ Task appears in task list")
                    else:
                        self.print_warning("Task not found in list (timing issue?)")
                else:
                    self.print_error("Failed to retrieve task list")

                self.print_workflow("Step 3", "Monitoring background agent activity...")

                # Monitor for agent outputs
                max_checks = 6  # 30 seconds of checking
                output_found = False

                for i in range(max_checks):
                    await asyncio.sleep(5)
                    response = await client.get(f"{self.base_url}/api/v1/tasks/{task_id}/outputs")

                    if response.status_code == 200:
                        outputs = response.json()

                        if outputs:
                            self.print_success(f"‚úÖ Background agent outputs detected: {len(outputs)}")
                            latest_output = outputs[-1]
                            self.print_info(f"Latest output type: {latest_output.get('output_type')}")
                            self.print_info(f"Content preview: {latest_output.get('content', '')[:100]}...")
                            output_found = True
                            break
                        self.print_info(f"Checking for agent activity... ({i+1}/{max_checks})")
                    else:
                        self.print_warning("Failed to check agent outputs")
                        break

                if not output_found:
                    self.print_warning("No agent outputs detected (agents may be slow to start)")
                    self.print_info("This is normal - background jobs can take time to initialize")

                self.print_workflow("Step 4", "Validating task monitoring capabilities...")

                # Get final task details
                response = await client.get(f"{self.base_url}/api/v1/tasks/{task_id}")
                if response.status_code == 200:
                    task_details = response.json()
                    self.print_success("‚úÖ Task monitoring endpoint works")
                    self.print_info(f"Task status: {task_details.get('task_status')}")
                    self.print_info(f"Kubernetes status: {task_details.get('status')}")
                    self.print_info(f"Variations: {task_details.get('variations')}")
                else:
                    self.print_error("Task monitoring failed")

                # Summary
                self.print_success("üéâ Background workflow simulation complete!")
                self.print_info("üìã Workflow Summary:")
                self.print_info("   1. ‚úÖ Task submission via API")
                self.print_info("   2. ‚úÖ Background job creation")
                self.print_info("   3. ‚úÖ Agent output monitoring")
                self.print_info("   4. ‚úÖ Task status tracking")

                self.print_workflow("Architecture Match", "‚úÖ Matches OpenAI Codex / Cursor.com background pattern")

                self.record_result("Background Workflow", True)
                return True

        except Exception as e:
            self.print_error(f"Background workflow simulation failed: {e}")
            self.record_result("Background Workflow", False, str(e))
            return False

    def print_final_summary(self):
        """Print comprehensive final summary."""
        self.print_header("üéØ FINAL VALIDATION SUMMARY", "üéØ")

        passed = sum(1 for _, success, _ in self.results if success)
        total = len(self.results)

        print(f"{Colors.BOLD}Test Results: {passed}/{total} passed{Colors.ENDC}\n")

        # Print detailed results
        for test_name, success, details in self.results:
            status = f"{Colors.GREEN}‚úÖ" if success else f"{Colors.RED}‚ùå"
            print(f"{status} {test_name}{Colors.ENDC}")
            if details and not success:
                print(f"   {Colors.GRAY}‚îî‚îÄ {details}{Colors.ENDC}")

        print(f"\n{Colors.PURPLE}{'='*70}{Colors.ENDC}")

        if passed == total:
            print(f"{Colors.GREEN}{Colors.BOLD}üéâ ALL SYSTEMS OPERATIONAL! üéâ{Colors.ENDC}")
            print(f"{Colors.GREEN}Your AIdeator environment is ready for background processing.{Colors.ENDC}")

            print(f"\n{Colors.CYAN}üöÄ QUICK START:{Colors.ENDC}")
            print(f"{Colors.WHITE}‚Ä¢ Frontend: http://localhost:3000{Colors.ENDC}")
            print(f"{Colors.WHITE}‚Ä¢ API Docs: http://localhost:8000/docs{Colors.ENDC}")
            print(f"{Colors.WHITE}‚Ä¢ Submit tasks via main page ‚Üí Monitor via task detail pages{Colors.ENDC}")

            print(f"\n{Colors.BLUE}üìö ARCHITECTURE REFERENCES:{Colors.ENDC}")
            print(f"{Colors.WHITE}‚Ä¢ OpenAI Codex: Background coding agents in ChatGPT interface{Colors.ENDC}")
            print(f"{Colors.WHITE}‚Ä¢ Cursor.com: Autonomous background code generation{Colors.ENDC}")
            print(f"{Colors.WHITE}‚Ä¢ Pattern: Submit ‚Üí Background Process ‚Üí Monitor Progress{Colors.ENDC}")

        else:
            failed = total - passed
            print(f"{Colors.YELLOW}‚ö†Ô∏è  {failed} issues found. Check details above.{Colors.ENDC}")

            print(f"\n{Colors.BLUE}üí° COMMON FIXES:{Colors.ENDC}")
            print(f"{Colors.WHITE}‚Ä¢ Missing services: tilt up{Colors.ENDC}")
            print(f"{Colors.WHITE}‚Ä¢ Database issues: tilt trigger database-migrate{Colors.ENDC}")
            print(f"{Colors.WHITE}‚Ä¢ API key issues: Check .env file{Colors.ENDC}")

        print(f"\n{Colors.PURPLE}{'='*70}{Colors.ENDC}")

    async def run_all_checks(self):
        """Run all validation checks."""
        print(f"{Colors.CYAN}{Colors.BOLD}")
        print("üöÄ AIdeator Complete Environment & Architecture Checker")
        print("=" * 70)
        print("Validating background processing workflow like OpenAI Codex & Cursor.com")
        print(f"{'=' * 70}{Colors.ENDC}")

        # Run all checks
        await asyncio.gather(
            asyncio.create_task(self.check_environment_files_async()),
            asyncio.create_task(self.check_application_settings_async()),
        )

        await self.check_database_schema()
        await self.check_redis_cache()
        await self.check_kubernetes_cluster()
        await self.check_api_architecture()
        await self.simulate_background_workflow()

        self.print_final_summary()

        # Return exit code
        passed = sum(1 for _, success, _ in self.results if success)
        total = len(self.results)
        return 0 if passed == total else 1

    async def check_environment_files_async(self):
        """Async wrapper for environment files check."""
        return self.check_environment_files()

    async def check_application_settings_async(self):
        """Async wrapper for application settings check."""
        return self.check_application_settings()


async def main():
    """Main execution function."""
    checker = EnvironmentChecker()
    exit_code = await checker.run_all_checks()
    return exit_code


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
