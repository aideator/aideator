apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "aideator.fullname" . }}-litellm-config
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "aideator.labels" . | nindent 4 }}
    app.kubernetes.io/component: litellm-gateway
data:
  config.yaml: |
    model_list:
      # Wildcard patterns for dynamic model discovery
      - model_name: openai/*
        litellm_params:
          model: openai/*
          api_key: os.environ/OPENAI_API_KEY
      {{- if .Values.secrets.anthropic }}
      - model_name: anthropic/*
        litellm_params:
          model: anthropic/*
          api_key: os.environ/ANTHROPIC_API_KEY
      {{- end }}
      {{- if .Values.secrets.gemini }}
      - model_name: gemini/*
        litellm_params:
          model: gemini/*
          api_key: os.environ/GEMINI_API_KEY
      {{- end }}
      # Additional provider wildcards for comprehensive coverage
      - model_name: vertex_ai/*
        litellm_params:
          model: vertex_ai/*
          vertex_project: os.environ/VERTEX_PROJECT_ID
          vertex_location: os.environ/VERTEX_LOCATION
      - model_name: bedrock/*
        litellm_params:
          model: bedrock/*
          aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
          aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
          aws_region_name: os.environ/AWS_REGION
      - model_name: azure/*
        litellm_params:
          model: azure/*
          api_key: os.environ/AZURE_API_KEY
          api_base: os.environ/AZURE_API_BASE
          api_version: os.environ/AZURE_API_VERSION
      - model_name: mistral/*
        litellm_params:
          model: mistral/*
          api_key: os.environ/MISTRAL_API_KEY
      - model_name: cohere/*
        litellm_params:
          model: cohere/*
          api_key: os.environ/COHERE_API_KEY
      - model_name: groq/*
        litellm_params:
          model: groq/*
          api_key: os.environ/GROQ_API_KEY
      - model_name: deepseek/*
        litellm_params:
          model: deepseek/*
          api_key: os.environ/DEEPSEEK_API_KEY
      - model_name: perplexity/*
        litellm_params:
          model: perplexity/*
          api_key: os.environ/PERPLEXITY_API_KEY
      - model_name: together_ai/*
        litellm_params:
          model: together_ai/*
          api_key: os.environ/TOGETHER_API_KEY
      - model_name: huggingface/*
        litellm_params:
          model: huggingface/*
          api_key: os.environ/HUGGINGFACE_API_KEY
      - model_name: replicate/*
        litellm_params:
          model: replicate/*
          api_key: os.environ/REPLICATE_API_KEY
      - model_name: ollama/*
        litellm_params:
          model: ollama/*
          api_base: os.environ/OLLAMA_API_BASE
      - model_name: xai/*
        litellm_params:
          model: xai/*
          api_key: os.environ/XAI_API_KEY
      {{- if .Values.litellm.models }}
      {{- range .Values.litellm.models }}
      - model_name: {{ .name }}
        litellm_params:
          model: {{ .model }}
          {{- if .api_key }}
          api_key: {{ .api_key }}
          {{- end }}
          {{- if .api_base }}
          api_base: {{ .api_base }}
          {{- end }}
          {{- if .api_version }}
          api_version: {{ .api_version }}
          {{- end }}
      {{- end }}
      {{- end }}
    
    general_settings:
      master_key: os.environ/LITELLM_MASTER_KEY
      {{- if .Values.litellm.database.enabled }}
      database_url: {{ .Values.litellm.database.url | quote }}
      {{- else }}
      database_url: "sqlite:///litellm_proxy.db"
      {{- end }}
      {{- if .Values.litellm.cache.enabled }}
      cache: true
      cache_params:
        type: redis
        host: {{ include "aideator.fullname" . }}-redis
        port: 6379
        {{- if .Values.litellm.cache.ttl }}
        ttl: {{ .Values.litellm.cache.ttl }}
        {{- end }}
      {{- end }}
      {{- if .Values.litellm.callbacks }}
      callbacks: {{ .Values.litellm.callbacks | toJson }}
      {{- else }}
      callbacks: ["prometheus"]
      {{- end }}
      
    litellm_settings:
      drop_params: false
      set_verbose: {{ .Values.litellm.verbose | default false }}
      check_provider_endpoint: true  # Enable dynamic model discovery from provider endpoints
      {{- if .Values.litellm.timeout }}
      request_timeout: {{ .Values.litellm.timeout }}
      {{- end }}
      
    router_settings:
      model_group_alias:
        "gpt-4o-mini": "gpt-4o-mini"
        "gpt-4": "gpt-4"
        "gpt-3.5-turbo": "gpt-3.5-turbo"
        {{- if .Values.secrets.anthropic }}
        "claude-3-opus": "claude-3-opus"
        "claude-3-sonnet": "claude-3-sonnet"
        "claude-3-haiku": "claude-3-haiku"
        {{- end }}